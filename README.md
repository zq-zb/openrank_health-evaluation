# openrank_health-evaluation
健康度评估
# 实验过程步骤

## 1.数据获取处理操作
使用 python 将 从 opendigger 下载的top_300_metrics文件中json数据文件转换为 csv文件，并以其仓库+指标为名称，其中包含以下步骤

### ① 解析 json 函数（parse_opendigger_json）
	函数接收一个JSON文件路径作为参数，打开并读取该文件的内容，然后使用 json.load() 方法将其解析为Python字典对象 data ，并返回这个字典

### ② 写入 csv 函数（write_to_csv）
	接受解析后的数据字典 data 和 目标CSV文件路径作为参数。该函数打开指定的CSV文件，设置字段名（列标题）为“指标名称”和“指标值”，并将数据字典 data 中的每一项作为一行写入到CSV文件中。

### ③ 批量处理函数（batch_process_json_files）
	为了将 top_300_metrics 文件中所有的 json 文件都转换为 csv，手动操作效率总是极其低下的，此外，为了区别不同仓库中相同名称的指标数据，每个 csv 文件的名称都必须包含其仓库名称。
	函数接收根目录路径 ('./top_300_metrics') 和输出目录路径 ('./outputdata') 作为参数。使用os.walk()遍历根目录及其所有子目录，对于每个子目录，获取其名称以及父目录的名称。对于每个子目录中的JSON文件，构建完整的文件路径，分离文件名和扩展名，并根据父目录名、当前子目录名及文件的基本名称来构造新的CSV文件名。之后调用 ①（parse_opendigger_json）解析JSON文件内容，再通过 ②（write_to_csv）将解析的数据写入新命名的CSV文件中，最后打印出已处理的JSON文件路径以确认处理完成。

## 2.数据预处理操作

### 对数据的预处理：
#### 	① 将 contributor_email_suffixes 数据首先转化为 contributor 贡献者数量
	contributor_email_suffixes 数据首先转化为 贡献者数量，使得数据更直观：
	从指定目录'./outputdata'中找到所有以contributor_email_suffixes.csv为后缀的文件，处理这些文件中的数据，并将处理后的结果保存到新的 CSV 文件中。新文件名会保留原文件名中的仓库名（前两个 '_' 符号及前面包含的内容），并以 contributor.csv 为后缀，并存入输出路径('./contributor')

#### ② 将所有 csv 中缺失的时间数据补齐（依据各自仓库中的 active_dates_and_times.csv为时间基准）
	实现了批量处理CSV文件，确保每一组CSV文件中包含特定的日期列，并且这些文件中的日期条目与基准时间（active_dates_and_times）列表相匹配。对于每个需要处理的CSV文件，如果缺少指定的日期列（'指标名称'），则会添加该列并用NaN填充。将文件中的日期格式统一，并通过合并操作来检查和补全任何缺失的日期条目，确保所有文件都包含了完整的、与基准时间列表一致的日期序列。最后，处理后的文件会被保存到指定的输出目录中。
	此外：还存在某种情况，某仓库缺失了某指标数据的文件，则直接将改指标涉及的层面值为0
#### ③ 对缺失时间数据的数据进行补齐（将上述填补时间的数据值补齐）
对于数据的缺失，存在两种情况：
##### 1.该时间段确实没有具体数据产生而缺失时间数据，对应的指标数据值补0：
	使用 fillna(0) 将相关数据中数据值为 NaN 的补齐为 0
##### 	2.时间段由于出现特殊情况导致没有数据收集，产生数据缺失。
	1.使用平均数，众数等缺点：当数据值起伏波动交大时，后期的大数据的平均数，众数会影响到前期小数据的情况，这里与实际情况不相符程度较大。
	2.使用线性回归模型：当数据变化波动大等情况，易于导致其他填补的数据出现负值（实际情况不可能出现负值），而造成数据的填补不当
	3.这里采用模型的方法：K 近邻（KNN）填补
	KNN 算法可以根据样本之间的相似性，使用最相似的 k 个邻居的平均值来填补缺失值。对于时间序列数据，根据时间相近的数据点作为邻居，这样的数据更切合实际情况。

#### ④ 对复杂数据指标的处理
	问题，变更请求响应时间与解决持续时间这类的数据，则直接将其 avg 中的参数进行平均值求法，最终进行评分处理。
